{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import configparser\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('covid19-analytics.config'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = config.get('AWS', 'KEY')\n",
    "SECRET = config.get('AWS', 'SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_S3 = config.get('S3', 'SRC_S3')\n",
    "SRC_BUCKETS = config.get('S3', 'SRC_BUCKETS')\n",
    "SRC_REGION = config.get('S3', 'SRC_REGION')\n",
    "\n",
    "TARGET_S3 = config.get('S3', 'TARGET_S3')\n",
    "TARGET_OUTPUT_S3 = config.get('S3', 'TARGET_OUTPUT_S3')\n",
    "TARGET_REGION = config.get('S3', 'TARGET_REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_s3_client = boto3.client('s3', region_name=SRC_REGION)\n",
    "\n",
    "target_s3_client = boto3.client(\n",
    "    's3', \n",
    "    region_name=TARGET_REGION,\n",
    "    aws_access_key_id=KEY, \n",
    "    aws_secret_access_key=SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_s3_if_not_exists(bucket_name, bucket_region):\n",
    "    try:\n",
    "        # Check if bucket exists\n",
    "        target_s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    except ClientError as e:\n",
    "        # If ClientError is thrown then bucket does not exist\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == '404':\n",
    "            # Create bucket\n",
    "            target_s3_client.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration={'LocationConstraint': bucket_region}\n",
    "            )\n",
    "            print(f\"Bucket '{bucket_name}' created.\")\n",
    "        else:\n",
    "            print(e)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_objects_from_s3_to_s3(src_s3, src_buckets, target_s3):\n",
    "\n",
    "        src_buckets = src_buckets.split(',')\n",
    "        for src_bucket in src_buckets:\n",
    "            src_bucket = src_bucket.strip() # Remove any white spaces\n",
    "            print(f\"\\nAccessing src_bucket: {src_bucket}>>>\")\n",
    "\n",
    "            # s3 uses prefixes not folder structure so paginator iterates over src_bucket contents\n",
    "            paginator = src_s3_client.get_paginator('list_objects_v2')\n",
    "            for page in paginator.paginate(Bucket=src_s3, Prefix=src_bucket):\n",
    "                if 'Contents' in page:\n",
    "                    for obj in page['Contents']:\n",
    "                        copy_source = {'Bucket': src_s3, 'Key': obj['Key']}\n",
    "                        target_key = obj['Key'] # Same key in target bucket\n",
    "\n",
    "                        try:\n",
    "                            target_s3_client.head_object(Bucket=target_s3, Key=target_key)\n",
    "                            print(f\"Skipping {target_key}, already exists\")\n",
    "                            continue\n",
    "                        except ClientError as e:\n",
    "                            if e.response['Error']['Code'] == '404':\n",
    "                                print(f\"Copying {obj['Key']} to {target_s3}/{target_key}\")\n",
    "                                try:\n",
    "                                    target_s3_client.copy_object(\n",
    "                                        CopySource=copy_source, \n",
    "                                        Bucket=target_s3,\n",
    "                                        Key=target_key\n",
    "                                    )\n",
    "                                except ClientError as e:\n",
    "                                    print(f\"ClientError: {e}\")\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Exception: {e}\")\n",
    "                else:\n",
    "                    print(f\"No content in {src_bucket}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_s3_if_not_exists(TARGET_S3, TARGET_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_s3_if_not_exists(TARGET_OUTPUT_S3, TARGET_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_objects_from_s3_to_s3(SRC_S3, SRC_BUCKETS, TARGET_S3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
