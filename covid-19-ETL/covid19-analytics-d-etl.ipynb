{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import configparser\n",
    "from io import StringIO\n",
    "\n",
    "import boto3\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/09 19:01:55 WARN Utils: Your hostname, codespaces-595706 resolves to a loopback address: 127.0.0.1; using 10.0.1.158 instead (on interface eth0)\n",
      "24/08/09 19:01:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/09 19:01:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Join\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('covid19-analytics.config'))\n",
    "\n",
    "KEY = config.get('AWS', 'KEY')\n",
    "SECRET = config.get('AWS', 'SECRET')\n",
    "\n",
    "TARGET_OUTPUT_BUCKET=config.get('S3', 'TARGET_OUTPUT_BUCKET')\n",
    "TARGET_OUTPUT_S3 = config.get('S3', 'TARGET_OUTPUT_S3')\n",
    "TARGET_OUTPUT_DIR=config.get('S3', 'TARGET_OUTPUT_DIR')\n",
    "TARGET_REGION = config.get('S3', 'TARGET_REGION')\n",
    "TMP_DIR = config.get('FILE_PATHS', 'TMP_DIR')\n",
    "\n",
    "DWH_CLUSTER_TYPE = config.get('DWH', 'DWH_CLUSTER_TYPE')\n",
    "DWH_NUM_NODES = config.get('DWH', 'DWH_NUM_NODES')\n",
    "DWH_NODE_TYPE = config.get('DWH', 'DWH_NODE_TYPE')\n",
    "DWH_CLUSTER_IDENTIFIER = config.get('DWH', 'DWH_CLUSTER_IDENTIFIER')\n",
    "DWH_DB = config.get('DWH', 'DWH_DB')\n",
    "DWH_DB_USER = config.get('DWH', 'DWH_DB_USER')\n",
    "DWH_DB_PASSWORD = config.get('DWH', 'DWH_DB_PASSWORD')\n",
    "DWH_PORT = config.get('DWH', 'DWH_PORT')\n",
    "DWH_IAM_ROLE_NAME = config.get('DWH', 'DWH_IAM_ROLE_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_S3_CLIENT = boto3.client(\n",
    "    's3', \n",
    "    region_name=TARGET_REGION,\n",
    "    aws_access_key_id=KEY, \n",
    "    aws_secret_access_key=SECRET\n",
    ")\n",
    "\n",
    "redshift_client = boto3.client(\n",
    "    'redshift',\n",
    "    region_name=TARGET_REGION,\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")\n",
    "\n",
    "ec2_client = boto3.resource(\n",
    "    'ec2',\n",
    "    region_name=TARGET_REGION,\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")\n",
    "\n",
    "iam_client = boto3.client(\n",
    "    'iam',\n",
    "    region_name=TARGET_REGION,\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/09 19:02:08 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "enigma_jhu = pd.read_csv(f'{TMP_DIR}/enigma_jhu.csv')\n",
    "testing_data_states_daily = pd.read_csv(f'{TMP_DIR}/testing-datastates_daily.csv')\n",
    "\n",
    "factCovid_1 = enigma_jhu[['fips', 'province_state', 'country_region', 'confirmed', 'deaths', 'recovered', 'active' ]]\n",
    "factCovid_2 = testing_data_states_daily[['fips', 'date', 'positive', 'negative', 'hospitalizedcurrently', 'hospitalized', 'hospitalizeddischarged' ]]\n",
    "factCovid = pd.merge(factCovid_1, factCovid_2, on='fips', how='inner')\n",
    "print(len(factCovid))\n",
    "\n",
    "factCovid = factCovid.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimHospital = pd.read_csv(f'{TMP_DIR}/hospital-bedsjson.csv')\n",
    "dimHospital =  dimHospital[['fips', 'state_name', 'latitude', 'longtitude', 'hq_address', 'hospital_name', 'hospital_type', 'hq_city', 'hq_state']]\n",
    "dimHospital = dimHospital.rename(columns={'longtitude': 'longitude'})\n",
    "\n",
    "dimHospital = dimHospital.drop_duplicates(keep='first')\n",
    "\n",
    "dimHospital['latitude'] = pd.to_numeric(dimHospital['latitude'], errors= 'coerce')\n",
    "dimHospital['longitude'] = pd.to_numeric(dimHospital['longitude'], errors= 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimDate = pd.read_csv(f'{TMP_DIR}/testing-datastates_daily.csv')\n",
    "dimDate = dimDate[['fips', 'date']]\n",
    "\n",
    "dimDate['date'] = pd.to_datetime(dimDate['date'], format='%Y%m%d')\n",
    "dimDate['year'] = dimDate['date'].dt.year\n",
    "dimDate['month'] = dimDate['date'].dt.month\n",
    "dimDate[\"day_of_week\"] = dimDate['date'].dt.dayofweek\n",
    "\n",
    "dimDate = dimDate.drop_duplicates(keep='first')\n",
    "\n",
    "dimDate['fips'] = dimDate['fips'].astype(float)\n",
    "dimDate['date'] = pd.to_datetime(dimDate['date'], errors= 'coerce')\n",
    "dimDate['date'] = dimDate['date'].astype('datetime64[ns]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "enigma_jhu = spark.read.csv(\n",
    "    f'{TMP_DIR}/enigma_jhu.csv', \n",
    "    header=True, \n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "ny_times_us_county = spark.read.csv(\n",
    "    f'{TMP_DIR}/us_county.csv', \n",
    "    header=True, \n",
    "    inferSchema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimRegion_1 = enigma_jhu.select('fips', 'province_state', 'country_region', 'latitude', 'longitude')\n",
    "dimRegion_2 = ny_times_us_county.select('fips', 'county', 'state')\n",
    "\n",
    "dimRegion_1 = dimRegion_1.repartition(4, 'fips')\n",
    "dimRegion_2 = dimRegion_2.repartition(4, 'fips')\n",
    "dimRegion_2 = dimRegion_2.withColumnRenamed('fips', 'fips2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimRegion = dimRegion_1.join(\n",
    "    dimRegion_2, \n",
    "    dimRegion_1[\"fips\"] == dimRegion_2[\"fips2\"], \n",
    "    \"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8660980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dimRegion = dimRegion.drop('fips2')\n",
    "print(dimRegion.count())\n",
    "\n",
    "dimRegion = dimRegion.distinct()\n",
    "print(dimRegion.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dimRegion = dimRegion.toPandas()\n",
    "dimRegion['fips'] = dimRegion['fips'].astype(float)\n",
    "\n",
    "dimRegion['latitude'] = pd.to_numeric(dimRegion['latitude'], errors= 'coerce')\n",
    "dimRegion['longitude'] = pd.to_numeric(dimRegion['longitude'], errors= 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "factCovid.to_csv(f\"{TMP_DIR}/factCovid.csv\")\n",
    "\n",
    "OUTPUT_S3_CLIENT.upload_file(\n",
    "    f\"{TMP_DIR}/factCovid.csv\",\n",
    "    Bucket=TARGET_OUTPUT_S3,\n",
    "    Key=f'{TARGET_OUTPUT_DIR}/factCovid.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimHospital.to_csv(f\"{TMP_DIR}/dimHospital.csv\")\n",
    "\n",
    "OUTPUT_S3_CLIENT.upload_file(\n",
    "    f\"{TMP_DIR}/dimHospital.csv\",\n",
    "    Bucket=TARGET_OUTPUT_S3,\n",
    "    Key=f'{TARGET_OUTPUT_DIR}/dimHospital.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimDate.to_csv(f\"{TMP_DIR}/dimDate.csv\")\n",
    "\n",
    "OUTPUT_S3_CLIENT.upload_file(\n",
    "    f\"{TMP_DIR}/dimDate.csv\",\n",
    "    Bucket=TARGET_OUTPUT_S3,\n",
    "    Key=f'{TARGET_OUTPUT_DIR}/dimDate.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimRegion.to_csv(f\"{TMP_DIR}/dimRegion.csv\")\n",
    "\n",
    "OUTPUT_S3_CLIENT.upload_file(\n",
    "    f\"{TMP_DIR}/dimRegion.csv\",\n",
    "    Bucket=TARGET_OUTPUT_S3,\n",
    "    Key=f'{TARGET_OUTPUT_DIR}/dimRegion.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm -r -f {TMP_DIR}/* # Cleanup tmp directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"factCovid\" (\n",
      "\"index\" INTEGER,\n",
      "  \"fips\" REAL,\n",
      "  \"province_state\" TEXT,\n",
      "  \"country_region\" TEXT,\n",
      "  \"confirmed\" REAL,\n",
      "  \"deaths\" REAL,\n",
      "  \"recovered\" REAL,\n",
      "  \"active\" TEXT,\n",
      "  \"date\" INTEGER,\n",
      "  \"positive\" REAL,\n",
      "  \"negative\" REAL,\n",
      "  \"hospitalizedcurrently\" REAL,\n",
      "  \"hospitalized\" REAL,\n",
      "  \"hospitalizeddischarged\" REAL\n",
      ");\n",
      "CREATE TABLE \"dimHospital\" (\n",
      "\"index\" INTEGER,\n",
      "  \"fips\" REAL,\n",
      "  \"state_name\" TEXT,\n",
      "  \"latitude\" REAL,\n",
      "  \"longitude\" REAL,\n",
      "  \"hq_address\" TEXT,\n",
      "  \"hospital_name\" TEXT,\n",
      "  \"hospital_type\" TEXT,\n",
      "  \"hq_city\" TEXT,\n",
      "  \"hq_state\" TEXT\n",
      ");\n",
      "CREATE TABLE \"dimDate\" (\n",
      "\"index\" INTEGER,\n",
      "  \"fips\" REAL,\n",
      "  \"date\" TIMESTAMP,\n",
      "  \"year\" INTEGER,\n",
      "  \"month\" INTEGER,\n",
      "  \"day_of_week\" INTEGER\n",
      ");\n",
      "CREATE TABLE \"dimRegion\" (\n",
      "\"index\" INTEGER,\n",
      "  \"fips\" REAL,\n",
      "  \"province_state\" TEXT,\n",
      "  \"country_region\" TEXT,\n",
      "  \"latitude\" REAL,\n",
      "  \"longitude\" REAL,\n",
      "  \"county\" TEXT,\n",
      "  \"state\" TEXT\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "# Construct CREATE TABLE SQL dynamically from pandas dataframe\n",
    "factCovid_sql = f\"{pd.io.sql.get_schema(factCovid.reset_index(), 'factCovid')};\"\n",
    "staging_factCovid_sql =  f\"{pd.io.sql.get_schema(factCovid.reset_index(), 'staging_factCovid')};\"\n",
    "print(factCovid_sql)\n",
    "\n",
    "dimHospital_sql = f\"{pd.io.sql.get_schema(dimHospital.reset_index(), 'dimHospital')};\"\n",
    "staging_dimHospital_sql = f\"{pd.io.sql.get_schema(dimHospital.reset_index(), 'staging_dimHospital')};\"\n",
    "print(dimHospital_sql)\n",
    "\n",
    "dimDate_sql = f\"{pd.io.sql.get_schema(dimDate.reset_index(), 'dimDate')};\"\n",
    "staging_dimDate_sql = f\"{pd.io.sql.get_schema(dimDate.reset_index(), 'staging_dimDate')};\"\n",
    "print(dimDate_sql)\n",
    "\n",
    "dimRegion_sql = f\"{pd.io.sql.get_schema(dimRegion.reset_index(), 'dimRegion')};\"\n",
    "staging_dimRegion_sql = f\"{pd.io.sql.get_schema(dimRegion.reset_index(), 'staging_dimRegion')};\"\n",
    "print(dimRegion_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method implements retries while obtaining redshift properties in case creating cluster is yet complete\n",
    "def get_redshift_props(redshift_client, cluster_identifier):\n",
    "    retries = 30\n",
    "    retry_delay = 30 # Delay between retries in seconds\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            clusterProps = redshift_client.describe_clusters(ClusterIdentifier=cluster_identifier)['Clusters'][0]\n",
    "            if clusterProps['ClusterAvailabilityStatus'] == 'Available':\n",
    "                return clusterProps\n",
    "            elif clusterProps['ClusterAvailabilityStatus'] != 'Available':\n",
    "                if attempt < retries -1:\n",
    "                    print(f\"Cluster '{cluster_identifier}' not ready. Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "        except redshift_client.exceptions.ClusterNotFoundFault as e:\n",
    "            if attempt < retries -1:\n",
    "                print(f\"Cluster '{cluster_identifier}' not found. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay/3)\n",
    "            else:\n",
    "                raise e # Raise the last exception if the retries are exhausted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_redshift_props(props):\n",
    "    pd.set_option('display.max.colwidth', 0)\n",
    "    keysToShow = ['ClusterIdentifier', 'ClusterStatus', 'NodeType', 'NumberOfNodes', 'DBName', 'MasterUsername', 'Endpoint', 'VpcId']\n",
    "    x = [(k, v) for k, v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=['Parameter', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterProps = get_redshift_props(redshift_client, DWH_CLUSTER_IDENTIFIER)\n",
    "if clusterProps:\n",
    "    prettyClusterProps = pretty_redshift_props(clusterProps)\n",
    "    DWH_ENDPOINT = clusterProps['Endpoint']['Address']\n",
    "    DWH_ROLE_ARN = clusterProps['IamRoles'][0]['IamRoleArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>covid19-redshift-cluster-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>oseloka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>covid19-redshift-db-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'covid19-redshift-cluster-1.covkciolfldm.us-east-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-0af307b31fe59e41a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Parameter  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                                   value  \n",
       "0  covid19-redshift-cluster-1                                                                             \n",
       "1  dc2.large                                                                                              \n",
       "2  available                                                                                              \n",
       "3  oseloka                                                                                                \n",
       "4  covid19-redshift-db-1                                                                                  \n",
       "5  {'Address': 'covid19-redshift-cluster-1.covkciolfldm.us-east-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-0af307b31fe59e41a                                                                                  \n",
       "7  1                                                                                                      "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prettyClusterProps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-019036ec555f0d73b')\n",
      "Security group rule exists, no further actions required\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2_client.Vpc(id=clusterProps['VpcId'])\n",
    "    default_SG = list(vpc.security_groups.all())[0]\n",
    "    print(default_SG)\n",
    "\n",
    "    default_SG.authorize_ingress(\n",
    "        GroupName=default_SG.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT),\n",
    "    )\n",
    "except ClientError as e:\n",
    "    # Check for duplicate rule errors\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == 'InvalidPermission.Duplicate':\n",
    "        print('Security group rule exists, no further actions required')\n",
    "    else:\n",
    "        raise e\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DWH_ENDPOINT,\n",
    "        dbname=DWH_DB,\n",
    "        user=DWH_DB_USER,\n",
    "        password=DWH_DB_PASSWORD,\n",
    "        port=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur = conn.cursor()\n",
    "except Exception as e:\n",
    "    print(\"Error: Could not obtain database cursor\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation \"staging_factcovid\" already exists\n",
      "\n",
      "Relation \"staging_dimhospital\" already exists\n",
      "\n",
      "Relation \"staging_dimdate\" already exists\n",
      "\n",
      "Relation \"staging_dimregion\" already exists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create tables\n",
    "try:\n",
    "    cur.execute(staging_factCovid_sql)\n",
    "    cur.execute(factCovid_sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    cur.execute(staging_dimHospital_sql)\n",
    "    cur.execute(dimHospital_sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    cur.execute(staging_dimDate_sql)\n",
    "    cur.execute(dimDate_sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    cur.execute(staging_dimRegion_sql)\n",
    "    cur.execute(dimRegion_sql)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>date</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>hospitalizedcurrently</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>hospitalizeddischarged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20210307</td>\n",
       "      <td>101327.0</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20210306</td>\n",
       "      <td>101327.0</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips province_state country_region  confirmed  deaths  recovered active  \\\n",
       "0  72.0  Puerto Rico    US             3.0        0.0     0.0        NaN     \n",
       "1  72.0  Puerto Rico    US             3.0        0.0     0.0        NaN     \n",
       "\n",
       "       date  positive  negative  hospitalizedcurrently  hospitalized  \\\n",
       "0  20210307  101327.0  305972.0  147.0                 NaN             \n",
       "1  20210306  101327.0  305972.0  147.0                 NaN             \n",
       "\n",
       "   hospitalizeddischarged  \n",
       "0 NaN                      \n",
       "1 NaN                      "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factCovid.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips       date  year  month  day_of_week\n",
       "0  2.0  2021-03-07  2021  3      6          \n",
       "1  1.0  2021-03-07  2021  3      6          "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimDate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53061.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>48.033</td>\n",
       "      <td>-121.834</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44007.0</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>US</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-71.413</td>\n",
       "      <td>Providence</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fips province_state country_region  latitude  longitude      county  \\\n",
       "0  53061.0  Washington     US             48.033   -121.834    Snohomish    \n",
       "1  44007.0  Rhode Island   US             41.824   -71.413     Providence   \n",
       "\n",
       "          state  \n",
       "0  Washington    \n",
       "1  Rhode Island  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimRegion.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>state_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hq_address</th>\n",
       "      <th>hospital_name</th>\n",
       "      <th>hospital_type</th>\n",
       "      <th>hq_city</th>\n",
       "      <th>hq_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4013.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.495498</td>\n",
       "      <td>-112.066157</td>\n",
       "      <td>650 E Indian School Rd</td>\n",
       "      <td>Phoenix VA Health Care System (AKA Carl T Hayden VA Medical Center)</td>\n",
       "      <td>VA Hospital</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4019.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>32.181263</td>\n",
       "      <td>-110.965885</td>\n",
       "      <td>3601 S 6th Ave</td>\n",
       "      <td>Southern Arizona VA Health Care System</td>\n",
       "      <td>VA Hospital</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fips state_name   latitude   longitude              hq_address  \\\n",
       "0  4013.0  Arizona    33.495498 -112.066157  650 E Indian School Rd   \n",
       "1  4019.0  Arizona    32.181263 -110.965885  3601 S 6th Ave           \n",
       "\n",
       "                                                         hospital_name  \\\n",
       "0  Phoenix VA Health Care System (AKA Carl T Hayden VA Medical Center)   \n",
       "1  Southern Arizona VA Health Care System                                \n",
       "\n",
       "  hospital_type  hq_city hq_state  \n",
       "0  VA Hospital   Phoenix  AZ       \n",
       "1  VA Hospital   Tucson   AZ       "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimHospital.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\n",
    "    f\"\"\"\n",
    "    copy staging_dimhospital\n",
    "    from '{TARGET_OUTPUT_BUCKET}dimHospital.csv'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter ','\n",
    "    region '{TARGET_REGION}'\n",
    "    IGNOREHEADER 1\n",
    "    EMPTYASNULL\n",
    "    BLANKSASNULL\n",
    "    MAXERROR 100\n",
    "    \"\"\"\n",
    "    )\n",
    "except ClientError as error:\n",
    "    print(error)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\n",
    "    f\"\"\"\n",
    "    copy staging_factCovid\n",
    "    from '{TARGET_OUTPUT_BUCKET}factCovid.csv'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter ','\n",
    "    region '{TARGET_REGION}'\n",
    "    IGNOREHEADER 1\n",
    "    EMPTYASNULL\n",
    "    BLANKSASNULL\n",
    "    MAXERROR 100\n",
    "    \"\"\"\n",
    "    )\n",
    "except ClientError as error:\n",
    "    print(error)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\n",
    "    f\"\"\"\n",
    "    copy staging_dimdate\n",
    "    from '{TARGET_OUTPUT_BUCKET}dimDate.csv'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter ','\n",
    "    region '{TARGET_REGION}'\n",
    "    IGNOREHEADER 1\n",
    "    EMPTYASNULL\n",
    "    BLANKSASNULL\n",
    "    MAXERROR 100\n",
    "    \"\"\"\n",
    "    )\n",
    "except ClientError as error:\n",
    "    print(error)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\n",
    "    f\"\"\"\n",
    "    copy staging_dimRegion\n",
    "    from '{TARGET_OUTPUT_BUCKET}dimRegion.csv'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter ','\n",
    "    region '{TARGET_REGION}'\n",
    "    IGNOREHEADER 1\n",
    "    EMPTYASNULL\n",
    "    BLANKSASNULL\n",
    "    MAXERROR 100\n",
    "    \"\"\"\n",
    "    )\n",
    "except ClientError as error:\n",
    "    print(error)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fips,province_state,country_region,confirmed,deaths,recovered,active,date,positive,negative,hospitalizedcurrently,hospitalized,hospitalizeddischarged'}\n",
      "{'sub.fips,sub.province_state,sub.country_region,sub.confirmed,sub.deaths,sub.recovered,sub.active,sub.date,sub.positive,sub.negative,sub.hospitalizedcurrently,sub.hospitalized,sub.hospitalizeddischarged'}\n"
     ]
    }
   ],
   "source": [
    "columns = [col for col in factCovid.columns if col != 'index']\n",
    "\n",
    "\n",
    "select_cols = ({','.join(columns)})\n",
    "select_sub = {','.join([f'sub.{col}' for col in columns])}\n",
    "\n",
    "print(select_cols)\n",
    "print(select_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting unique 'dimHospital' records using all columes exclusing 'index' to verify uniqueness\n",
    "columns = [col for col in dimHospital.columns if col != 'index']\n",
    "\n",
    "insert_dimHospital = f\"\"\"\n",
    "insert into dimHospital ({','.join(columns)})\n",
    "select {','.join([f'sub.{col}' for col in columns])}\n",
    "from (\n",
    "    select {','.join(columns)},\n",
    "        row_number() over (partition by {','.join(columns)} order by index) as row_num\n",
    "    from staging_dimHospital\n",
    ") sub\n",
    "where row_num = 1;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Inserting unique 'dimDate' records using all columes exclusing 'index' to verify uniqueness\n",
    "columns = [col for col in dimDate.columns if col != 'index']\n",
    "\n",
    "insert_dimDate = f\"\"\"\n",
    "insert into dimDate ({','.join(columns)})\n",
    "select {','.join([f'sub.{col}' for col in columns])}\n",
    "from (\n",
    "    select {','.join(columns)},\n",
    "        row_number() over (partition by {','.join(columns)} order by index) as row_num\n",
    "    from staging_dimDate\n",
    ") sub\n",
    "where row_num = 1;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Inserting unique 'dimRegion' records using all columes exclusing 'index' to verify uniqueness\n",
    "columns = [col for col in dimRegion.columns if col != 'index']\n",
    "\n",
    "insert_dimRegion = f\"\"\"\n",
    "insert into dimRegion ({','.join(columns)})\n",
    "select {','.join([f'sub.{col}' for col in columns])}\n",
    "from (\n",
    "    select {','.join(columns)},\n",
    "        row_number() over (partition by {','.join(columns)} order by index) as row_num\n",
    "    from staging_dimRegion\n",
    ") sub\n",
    "where row_num = 1;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Inserting unique 'factCovid' records using all columes exclusing 'index' to verify uniqueness\n",
    "columns = [col for col in factCovid.columns if col != 'index']\n",
    "\n",
    "insert_factCovid = f\"\"\"\n",
    "insert into factCovid ({','.join(columns)})\n",
    "select {','.join([f'sub.{col}' for col in columns])}\n",
    "from (\n",
    "    select {','.join(columns)},\n",
    "    from staging_factCovid\n",
    ") sub\n",
    "where row_num = 1;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error at or near \"from\" in context \",hospitalizeddischarged,\n",
      "    from\", at line 6, column 5\n",
      "LINE 6:     from staging_factCovid\n",
      "            ^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur.execute(insert_factCovid)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m column_names \u001b[38;5;241m=\u001b[39m [desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m desc \u001b[38;5;129;01min\u001b[39;00m cur\u001b[38;5;241m.\u001b[39mdescription]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "column_names = [desc[0] for desc in cur.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows =cur.fetchmany(10)\n",
    "print(column_names)\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"select * from users;\")\n",
    "except Exception as e:\n",
    "    print(\"Unable to select from 'users' table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows =cur.fetchmany(10)\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "try:\n",
    "    conn.close()\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redshift_client.delete_cluster(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER, SkipFinalClusterSnapshot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
